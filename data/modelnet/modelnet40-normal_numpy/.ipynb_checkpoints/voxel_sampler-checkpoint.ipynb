{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numbers\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import struct\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import faiss\n",
    "import pcl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib qt5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNBuilder_GPU:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.dimension = 3\n",
    "        \n",
    "        # we need only a StandardGpuResources per GPU\n",
    "        self.res = faiss.StandardGpuResources()\n",
    "#         self.res.setTempMemoryFraction(0.2)\n",
    "        self.flat_config = faiss.GpuIndexFlatConfig()\n",
    "        self.flat_config.device = 0\n",
    "        \n",
    "    def build_nn_index(self, database):\n",
    "        '''\n",
    "        :param database: numpy array of Nx3\n",
    "        :return: Faiss index, in CPU\n",
    "        '''\n",
    "        index = faiss.GpuIndexFlatL2(self.res, self.dimension, self.flat_config)  # dimension is 3\n",
    "        index.add(database)\n",
    "        return index\n",
    "    \n",
    "    def search_nn(self, index, query, k):\n",
    "        '''\n",
    "        :param index: Faiss index\n",
    "        :param query: numpy array of Nx3\n",
    "        :return: D: numpy array of Nxk\n",
    "                 I: numpy array of Nxk\n",
    "        '''\n",
    "        D, I = index.search(query, k)\n",
    "        return D, I\n",
    "    \n",
    "    def self_build_search(self, x):\n",
    "        '''\n",
    "\n",
    "        :param x: numpy array of Nxd\n",
    "        :return: D: numpy array of Nxk\n",
    "                 I: numpy array of Nxk\n",
    "        '''\n",
    "        x = np.ascontiguousarray(x, dtype=np.float32)\n",
    "        index = self.build_nn_index(x)\n",
    "        D, I = self.search_nn(index, x, self.k)\n",
    "        return D, I\n",
    "    \n",
    "\n",
    "class KNNBuilder:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.dimension = 3\n",
    "\n",
    "    def build_nn_index(self, database):\n",
    "        '''\n",
    "        :param database: numpy array of Nx3\n",
    "        :return: Faiss index, in CPU\n",
    "        '''\n",
    "        index = faiss.IndexFlatL2(self.dimension)  # dimension is 3\n",
    "        index.add(database)\n",
    "        return index\n",
    "\n",
    "    def search_nn(self, index, query, k):\n",
    "        '''\n",
    "        :param index: Faiss index\n",
    "        :param query: numpy array of Nx3\n",
    "        :return: D: numpy array of Nxk\n",
    "                 I: numpy array of Nxk\n",
    "        '''\n",
    "        D, I = index.search(query, k)\n",
    "        return D, I\n",
    "\n",
    "    def self_build_search(self, x):\n",
    "        '''\n",
    "\n",
    "        :param x: numpy array of Nxd\n",
    "        :return: D: numpy array of Nxk\n",
    "                 I: numpy array of Nxk\n",
    "        '''\n",
    "        x = np.ascontiguousarray(x, dtype=np.float32)\n",
    "        index = self.build_nn_index(x)\n",
    "        D, I = self.search_nn(index, x, self.k)\n",
    "        return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCSampler:\n",
    "    def __init__(self, leaf_size, minimum_pc_num, iteration):       \n",
    "        self.leaf_size = leaf_size\n",
    "        self.minimum_pc_num = minimum_pc_num\n",
    "        self.iteration = iteration\n",
    "    \n",
    "    def sample_pc(self, pc, leaf_size):\n",
    "        '''\n",
    "        :param pc: input numpy array of Nx3\n",
    "        :return: sampled_pc of Mx3\n",
    "        '''\n",
    "        cloud = pcl.PointCloud(pc)\n",
    "        sor = cloud.make_voxel_grid_filter()\n",
    "        sor.set_leaf_size(leaf_size, leaf_size, leaf_size)\n",
    "        cloud_filtered = sor.filter()\n",
    "        sampled_pc = np.asarray(cloud_filtered)\n",
    "        \n",
    "        return sampled_pc\n",
    "    \n",
    "    def sample_pc_wrapper(self, pc):\n",
    "        '''\n",
    "        ensure that the sampled pc is more than a certain amount\n",
    "        use binary search\n",
    "        '''\n",
    "        iteration = 0\n",
    "        \n",
    "        low, high = 0.01, self.leaf_size\n",
    "        pc_sampled_high = None\n",
    "        \n",
    "        while iteration<self.iteration:\n",
    "            mid = (low+high) / 2\n",
    "            pc_sampled = self.sample_pc(pc, mid)\n",
    "            if pc_sampled.shape[0] < self.minimum_pc_num:\n",
    "                high = mid\n",
    "            elif pc_sampled.shape[0] > self.minimum_pc_num:\n",
    "                low = mid\n",
    "                pc_sampled_low = pc_sampled\n",
    "            else:\n",
    "                break\n",
    "            iteration += 1\n",
    "            \n",
    "        # debug\n",
    "#         print('low %f, high %f' % (low, high))\n",
    "        \n",
    "        \n",
    "        if pc_sampled.shape[0] < self.minimum_pc_num:\n",
    "            pc_sampled = pc_sampled_low\n",
    "        assert pc_sampled.shape[0] >= self.minimum_pc_num\n",
    "        return pc_sampled\n",
    "        \n",
    "    \n",
    "    \n",
    "def make_dataset_modelnet40_10k(root, is_train):\n",
    "    dataset = []\n",
    "    \n",
    "    f = open(os.path.join(root, 'modelnet40_shape_names.txt'))\n",
    "    shape_list = [str.rstrip() for str in f.readlines()]\n",
    "    f.close()\n",
    "    \n",
    "    if True==is_train:\n",
    "        f = open(os.path.join(root, 'modelnet40_train.txt'), 'r')\n",
    "        lines = [str.rstrip() for str in f.readlines()]\n",
    "        f.close()\n",
    "    else:\n",
    "        f = open(os.path.join(root, 'modelnet40_test.txt'), 'r')\n",
    "        lines = [str.rstrip() for str in f.readlines()]\n",
    "        f.close()\n",
    "    \n",
    "    for i, name in enumerate(lines):\n",
    "        # locate the folder name\n",
    "        folder = name[0:-5]\n",
    "        file_name = name\n",
    "        \n",
    "        # get the label\n",
    "        label = shape_list.index(folder)\n",
    "        \n",
    "        item = (os.path.join(folder, file_name+'.npy'),\n",
    "                label)\n",
    "        dataset.append(item)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def check_normalization(pc, intreval_max_threshold):\n",
    "    is_corrected = False\n",
    "    \n",
    "    pc_max = np.amax(pc, axis=0)\n",
    "    pc_min = np.amin(pc, axis=0)\n",
    "    interval = pc_max-pc_min\n",
    "    interval_max = np.amax(interval)\n",
    "\n",
    "    if interval_max < intreval_max_threshold:\n",
    "        pc_mean = np.mean(pc, axis=0)\n",
    "        pc = pc - pc_mean\n",
    "        pc_max_element = np.amax(pc)\n",
    "        positive_scale = 1.0 / pc_max_element\n",
    "        pc_min_element = np.amin(pc)\n",
    "        negative_scale = -1.0 / pc_min_element\n",
    "        \n",
    "        scale = min(positive_scale, negative_scale)\n",
    "        pc = pc * scale\n",
    "        \n",
    "        is_corrected = True\n",
    "  \n",
    "    # check interval\n",
    "    pc_max = np.amax(pc, axis=0)\n",
    "    pc_min = np.amin(pc, axis=0)\n",
    "    interval = pc_max-pc_min\n",
    "    interval_max = np.amax(interval)\n",
    "    assert interval_max > intreval_max_threshold\n",
    "#     print(interval_max)\n",
    "        \n",
    "    return pc, is_corrected\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxel_sample(root, is_train, minimum_pc_num):\n",
    "    new_root = root + '_%d'%minimum_pc_num\n",
    "    \n",
    "    # get shape_list\n",
    "    f = open(os.path.join(root, 'modelnet40_shape_names.txt'))\n",
    "    shape_list = [str.rstrip() for str in f.readlines()]\n",
    "    f.close()\n",
    "    \n",
    "    # build dataset\n",
    "    dataset = make_dataset_modelnet40_10k(root, is_train)\n",
    "    \n",
    "    # build sampler\n",
    "    sampler = PCSampler(leaf_size=0.1, minimum_pc_num=2048, iteration=9)\n",
    "    \n",
    "    # iterate over the samples\n",
    "    for i, item in enumerate(dataset):\n",
    "        pc_filename, label = item\n",
    "        pc_sn = np.load(os.path.join(root, pc_filename))\n",
    "        pc = pc_sn[:, 0:3]\n",
    "        \n",
    "        # check and correct wrongly normalized samples\n",
    "        pc, is_corrected = check_normalization(pc, intreval_max_threshold=1.0)\n",
    "        if is_corrected==True:\n",
    "            print(pc_filename)\n",
    "        \n",
    "        # perform voxel grid filter\n",
    "        pc_sampled = sampler.sample_pc_wrapper(pc)\n",
    "        np.random.shuffle(pc_sampled)\n",
    "        \n",
    "        # perform KNN search to get the surface normal\n",
    "        knn = KNNBuilder_GPU(k=1)\n",
    "        index = knn.build_nn_index(np.ascontiguousarray(pc, dtype=np.float32))\n",
    "        D, I = knn.search_nn(index, pc_sampled.astype(np.float32), k=1)\n",
    "        sn_sampled = pc_sn[:, 3:][I[:, 0]]\n",
    "        pc_sn_sampled = np.concatenate((pc_sampled, sn_sampled), axis=1)\n",
    "        \n",
    "        # debug\n",
    "#         print(pc_sn_sampled[0])\n",
    "#         print(pc_sn[I[0,0]])\n",
    "#         print(pc_sampled.shape)\n",
    "#         fig = plt.figure()\n",
    "#         ax = Axes3D(fig)\n",
    "#         ax.scatter(pc_sampled[:,0].tolist(), pc_sampled[:,1].tolist(), pc_sampled[:,2].tolist(), s=1, c=[0.5,0.5,0.5])\n",
    "#         plt.show()\n",
    "        \n",
    "        # save to new destination, i.e., new_root\n",
    "        if os.path.exists(os.path.join(new_root, shape_list[label]))==False:\n",
    "            os.makedirs(os.path.join(new_root, shape_list[label]))\n",
    "        np.save(os.path.join(new_root, pc_filename), pc_sn_sampled)\n",
    "        \n",
    "#         if i>10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_sample(root='/ssd/dataset/modelnet40-normal_numpy', is_train=True, minimum_pc_num=1024)\n",
    "voxel_sample(root='/ssd/dataset/modelnet40-normal_numpy', is_train=False, minimum_pc_num=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_sn = np.load('/ssd/dataset/modelnet40-normal_numpy/bottle/bottle_0064.npy')\n",
    "pc = pc_sn[:, 0:3]\n",
    "\n",
    "pc = check_normalization(pc, 1.0)\n",
    "\n",
    "# build sampler\n",
    "sampler = PCSampler(leaf_size=0.1, minimum_pc_num=2048, iteration=9)\n",
    "pc_sampled = sampler.sample_pc(pc, leaf_size=0.01)\n",
    "\n",
    "print(pc_sampled.shape)\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(pc_sampled[:,0].tolist(), pc_sampled[:,1].tolist(), pc_sampled[:,2].tolist(), s=1, c=[0.5,0.5,0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(1,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
